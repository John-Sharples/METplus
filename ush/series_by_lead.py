#!/usr/bin/python
from __future__ import print_function

import constants_pdef as P
import logging
import re
import os
import sys
import met_util as util
import errno

def main():
    # Create ConfigMaster parm object
    p = P.Params()
    p.init(__doc__)
    logger = util.get_logger(p)
    analysis_by_lead_time(p, logger)


def analysis_by_lead_time(p, logger):
    ''' Perform a series analysis of extra tropical cyclone
        paired data based on lead time (forecast hour) 
        This requires invoking the MET run_series_analysis binary,
        followed by generating graphics that are recognized by 
        the MET viewer using the plot_data_plane and convert.  
        A pre-requisite is the presence of the filter file and storm files
        (currently 30 x 30 degree tiles) for the specified init and lead times.
   

       Invoke the series_analysis script based on lead time (forecast hour) 
       Create the command:
         series_analysis -fcst <OUT_DIR>/FCST_FILES_F<CUR_FHR>
                         -obs <OUT_DIR>/ANLY_FILES_F<CUR_FHR>
                         -out <OUT_DIR>/series_F<CURR_FHR_<NAME>_<LEVEL>.nc 
                         -config SeriesAnalysisConfig_by_lead
      Args:
        p:          ConfigMaster parameter object 

        logger  :   The logging object to which logging will be saved.




      Returns:
        None:       Creates graphics plots for files corresponding to each
                    forecast lead time.


    '''

    # Create a param object
    p = P.Params()
    p.init(__doc__)

    logger = util.get_logger(p)
    
    cur_ = sys._getframe().f_code.co_filename
    cur_function = sys._getframe().f_code.co_name 
    
    # Retrieve any necessary values from the parm file(s)
    fhr_beg = p.opt["FHR_BEG"]
    fhr_end = p.opt["FHR_END"]
    fhr_inc = p.opt["FHR_INC"]
    fcst_tile_regex = p.opt["FCST_TILE_REGEX"]
    anly_tile_regex = p.opt["ANLY_TILE_REGEX"]
    fcst_ascii_regex = p.opt["FCST_ASCII_REGEX_LEAD"]
    anly_ascii_regex = p.opt["ANLY_ASCII_REGEX_LEAD"]
    proj_dir = p.opt["PROJ_DIR"]
    out_dir_base = p.opt["OUT_DIR"]
    var_list = p.opt["VAR_LIST"]
    stat_list = p.opt["STAT_LIST"]
    series_analysis_exe = p.opt["SERIES_ANALYSIS"]
    plot_data_plane_exe = p.opt["PLOT_DATA_PLANE"]
    convert_exe = p.opt["CONVERT_EXE"]
    rm_exe = p.opt["RM_EXE"]
    series_anly_configuration_file = p.opt["CONFIG_FILE_LEAD"]
 
    # Check for the existence of the storm track tiles and raise an error if these are missing.
    # Get a list of the grb2 forecast tiles in <proj_dir>/series_analysis/*/*/FCST_TILE_F<cur_fhr>.grb2
    tile_dir_parts = [proj_dir,'/series_analysis/']
    tile_dir = ''.join(tile_dir_parts)
    try:
        util.check_for_tiles(tile_dir, fcst_tile_regex, anly_tile_regex, logger)
    except OSError as e:
        logger.error("Missing 30x30 tile files.  Extract tiles needs to be run")
        raise
        
    # Clean up any previous ASCII files that were generated by 
    # earlier runs of the series analysis.
    cleanup_lead_ascii(p, logger)    
  
    
    # Create the values for the -fcst, -obs, and other required
    # options for running the MET series_analysis binary.
    for cur_fhr in range(fhr_beg, fhr_end+1, fhr_inc):
        logger.info('Evaluating forecast hour ' + str(cur_fhr))

        # Create the output directory where the netCDF files
        # will be saved.
        #out_dir_parts = [out_dir_base, '/', 'series_F', str(cur_fhr)]
        # for testing and development use this
        out_dir_parts = [out_dir_base, '/python_lead/', 'series_F', str(cur_fhr)]
        out_dir = ''.join(out_dir_parts)
        util.mkdir_p(out_dir)
        
        # Gather all the forecast and analysis gridded tile files
        # so they can be saved in ASCII files.
        fcst_tiles = get_files(tile_dir,fcst_tile_regex,logger)
        tmp_fcst_tile = ''
        tmp_anly_tile = ''
        for cur_fcst_tile in fcst_tiles:
            match_fcst = re.match(fcst_tile_regex, cur_fcst_tile)
            if match_fcst:
                storm_subdir = match_fcst.group(0)
            else:
                logger.error("ERROR: No matching storm id found, exiting...")
                sys.exit()
            # Create the ASCII files for the forecast and analysis files.
            lead_out_dir_parms = [out_dir, '/series_F', str(cur_fhr)]
            lead_out_dir = ''.join(lead_out_dir_parms)
            fcst_files_hr_list = ['FCST_FILES_F', str(cur_fhr)]
            fcst_files_hr_dir = ''.join(fcst_files_hr_list)
            anly_files_hr_list = ['ANLY_FILES_F', str(cur_fhr)]
            anly_files_hr_dir = ''.join(anly_files_hr_list)
            ascii_fcst_tiles_path = os.path.join(lead_out_dir, fcst_files_hr_dir) 
            fcst_tile_filename = os.path.join(lead_out_dir, fcst_files_hr_dir)
            anly_tile_filename = os.path.join(lead_out_dir, anly_files_hr_dir)
            ascii_anly_file_parts = [lead_out_dir, 'FCST_FILE_F',str(cur_fcst)]
            ascii_anly_file = ''.join(ascii_anly_file_parts)
            ascii_fcst_file_parts = [lead_out_dir, 'ANLY_FILE_F',str(cur_fcst)]
            ascii_fcst_file = ''.join(ascii_fcst_file_parts)

 
            # Capture all the FCST tiles (full file path)
            logger.info('FCST tile files: '+ fcst_tiles_filename)
            tmp_fcst_tile += fcst_tile_filename
            tmp_fcst_tile += '\n'
   
            # Capture all the ANLY tiles (full file path)
            logger.info('ANLY tile files: '+ ascii_anly_tiles_filename)
            tmp_anly_tile += anly_tile_filename
            tmp_anly_tile += '\n' 
 
            
         # Now create the ASCII files
         try:
             with open(ascii_fcst_file, 'a') as f:
                  f.write(tmp_fcst_tile)
         except IOError as e:
             logger.error("ERROR: Could not create requested ASCII file: " + ascii_fcst_file)

         try:
             with open(ascii_anly_file, 'a') as f:
                  f.write(tmp_anly_file)
         except IOError as e:
             logger.error("ERROR: Could not create requested ASCII file: " + ascii_anly_file)

            
                       
                




def find_matching_tile(fcst_file, anly_tiles, logger):
    ''' Find the corresponding ANLY 30x30 tile file to the 
        fcst tile file.
       
        Args:
          fcst_file_list (string):  The fcst file (full path) that 
                               is used to derive the corresponding
                               analysis file name.
          anly_tiles : The list of all available 30x30 analysis tiles.
          
          logger     : The logger to which all logging messages are
                       directed.

        Returns:
          anly_from_fcst (string): The name of the analysis tile file
                                   that corresponds to the same lead time
                                   as the input fcst tile. 
    '''
    
    # Derive the ANLY file name from the FCST file.
    anly_from_fcst = re.sub(r'FCST','ANLY', fcst_file)

    if anly_from_fcst in anly_tiles:
        return anly_from_fcst
    else:
        return None



def get_files(filedir, filename_regex, logger):
    ''' Get all the files (with a particular
        naming format) by walking 
        through the directories.
    
        Args:
          filedir (String):  The topmost directory from which the
                             search begins.
          filename_regex (string):  The regular expression that
                                    defines the naming format
                                    of the files of interest.
       Returns:
          file_paths (string): a list of filenames (with full filepath)       

    '''
    file_paths = []
    # Walk the tree
    for root, directories, files in os.walk(filedir):
        for filename in files:
            # add it to the list only if it is a match
            # to the specified format
            #prog = re.compile(filename_regex)
            match = re.match(filename_regex, filename)
            
            if match:
                # Join the two strings to form the full
                # filepath.
                filepath = os.path.join(root,filename)
                file_paths.append(filepath)
            else:
                continue
    return file_paths

def cleanup_lead_ascii( p, logger):
    ''' Remove any pre-existing FCST and ANLY ASCII files created by previous
        runs of series_by_lead.
        
        Args:
           p      : The ConfigMaster, used to retrieve the parameter values
           logger:  The logger to which all log messages are directed.
     
        Returns:
           None:  Removes any existing FCST and ANLY ASCII files which contains all
                  the forecast and analysis gridded tiles.

        
        
    '''
    
    # Useful for logging
    cur_filename = sys._getframe().f_code.co_filename
    cur_function = sys._getframe().f_code.co_name
    fhr_beg = p.opt["FHR_BEG"]
    fhr_end = p.opt["FHR_END"]
    fhr_inc = p.opt["FHR_INC"]
    fcst_ascii_regex = p.opt["FCST_ASCII_REGEX_LEAD"]
    anly_ascii_regex = p.opt["ANLY_ASCII_REGEX_LEAD"]
    rm_exe = p.opt["RM_EXE"]
    out_dir_base = p.opt["OUT_DIR"]
 
    for cur_fhr in range(fhr_beg, fhr_end, fhr_inc):
        #out_dir_parts = [out_dir_base, '/', 'series_F', str(cur_fhr)]
        out_dir_parts = [out_dir_base, '/python_lead/', 'series_F', str(cur_fhr)]
        out_dir = ''.join(out_dir_parts)    
          
        for root,directories,files in os.walk(out_dir):
            for cur_file in files:
                fcst_match = re.match(fcst_ascii_regex, cur_file)
                anly_match = re.match(anly_ascii_regex, cur_file)
                rm_cmd_parts = [rm_exe, ' ', out_dir, '/', cur_file]
                rm_cmd = ''.join(rm_cmd_parts)
                if fcst_match:
                    os.system(rm_cmd)
                if anly_match:
                    os.system(rm_cmd)
             
       

if __name__ == "__main__":
    main()

